{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3356f29",
   "metadata": {},
   "source": [
    "## Enabling PyTorch distributed training support with Kaen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6212b1f0",
   "metadata": {},
   "source": [
    "Save  the latest version of the DC taxi model (as described in the chapter 11) to a `model_v1.py` file in the `src` directory using the `%%writefile` magic as shown in the first line of the following snippet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87a6950",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e223c065",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile src/model_v1.py\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import torch as pt\n",
    "import pytorch_lightning as pl\n",
    "from distutils.util import strtobool\n",
    "\n",
    "pt.set_default_dtype(pt.float64)\n",
    "class DcTaxiModel(pl.LightningModule):\n",
    "    def __init__(self, **kwargs):\n",
    "      super().__init__()\n",
    "      self.save_hyperparameters()\n",
    "      pt.manual_seed(int(self.hparams.seed))\n",
    "\n",
    "      self.step = 0    \n",
    "      self.start_ts = time.perf_counter()\n",
    "      self.train_val_rmse = pt.tensor(0.)\n",
    "\n",
    "      #create a list of hidden layer neurons, e.g. [3, 5, 8]\n",
    "      num_hidden_neurons = json.loads(self.hparams.num_hidden_neurons)\n",
    "\n",
    "      self.layers = pt.nn.Sequential(\n",
    "          pt.nn.Linear(int(self.hparams.num_features), num_hidden_neurons[0]),\n",
    "          pt.nn.ReLU(),\n",
    "          *self.build_hidden_layers(num_hidden_neurons, pt.nn.ReLU()),\n",
    "          pt.nn.Linear(num_hidden_neurons[-1], 1)\n",
    "      )\n",
    "\n",
    "      if 'batch_norm_linear_layers' in self.hparams \\\n",
    "        and strtobool(self.hparams.batch_norm_linear_layers):\n",
    "        self.layers = self.batch_norm_linear(self.layers)\n",
    "\n",
    "    def build_hidden_layers(self, num_hidden_neurons, activation):\n",
    "      linear_layers = [ pt.nn.Linear(num_hidden_neurons[i],\n",
    "          num_hidden_neurons[i+1]) for i in range(len(num_hidden_neurons) - 1) ]\n",
    "\n",
    "      classes = [activation.__class__] * len(num_hidden_neurons)\n",
    "\n",
    "      activation_instances = list(map(lambda x: x(), classes))\n",
    "\n",
    "      hidden_layer_activation_tuples = list(zip(linear_layers, activation_instances))\n",
    "\n",
    "      hidden_layers = [i for sublist in hidden_layer_activation_tuples for i in sublist]\n",
    "\n",
    "      return hidden_layers\n",
    "\n",
    "    def batch_norm_linear(self, layers):\n",
    "      idx_linear = list(filter(lambda x: type(x) is int, \n",
    "                  [idx if issubclass(layer.__class__, pt.nn.Linear) else None for idx, layer in enumerate(layers)]))\n",
    "      idx_linear.append(sys.maxsize)\n",
    "      layer_lists = [list(iter(layers[s:e])) for s, e in zip(idx_linear[:-1], idx_linear[1:])]\n",
    "      batch_norm_layers = [pt.nn.BatchNorm1d(layer[0].in_features) for layer in layer_lists]\n",
    "      batch_normed_layer_lists = [ [bn, *layers] for bn, layers in list(zip(batch_norm_layers, layer_lists)) ]\n",
    "      return pt.nn.Sequential(*[layer for nested_layer in batch_normed_layer_lists for layer in nested_layer ])\n",
    "\n",
    "    def batchToXy(self, batch):\n",
    "      batch = batch.squeeze_()\n",
    "      X, y = batch[:, 1:], batch[:, 0]\n",
    "      return X, y\n",
    "\n",
    "    def forward(self, X):\n",
    "      y_est = self.layers(X)\n",
    "      return y_est.squeeze_()\n",
    "    \n",
    "    def log(self, k, v, **kwargs):        \n",
    "        super().log(k, v,\n",
    "                on_step = kwargs['on_step'],\n",
    "                on_epoch = kwargs['on_epoch'],\n",
    "                prog_bar = kwargs['prog_bar'],\n",
    "                logger = kwargs['logger'],)\n",
    "        \n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        self.step += 1\n",
    "\n",
    "        X, y = self.batchToXy(batch) #unpack batch into features and label\n",
    "\n",
    "        y_est = self.forward(X)\n",
    "\n",
    "        loss = pt.nn.functional.mse_loss(y_est, y)\n",
    "\n",
    "        for k,v in {\n",
    "          \"train_step\": self.step,\n",
    "          \"train_mse\": loss.item(),\n",
    "          \"train_rmse\": loss.sqrt().item(),\n",
    "          \"train_steps_per_sec\": self.step / (time.perf_counter() - self.start_ts),\n",
    "\n",
    "        }.items():\n",
    "          self.log(k, v, step = self.step, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "        self.train_val_rmse = loss.sqrt()\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "      X, y = self.batchToXy(batch) \n",
    "\n",
    "      with pt.no_grad():\n",
    "          loss = pt.nn.functional.mse_loss(self.forward(X), y)\n",
    "\n",
    "      for k,v in {\n",
    "        \"val_mse\": loss.item(),\n",
    "        \"val_rmse\": loss.sqrt().item(),\n",
    "        \"train_val_rmse\": (self.train_val_rmse + loss.sqrt()).item(),\n",
    "      }.items():\n",
    "        self.log(k, v, step = self.step, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "      return loss\n",
    "      \n",
    "    def test_step(self, batch, batch_idx):\n",
    "      X, y = self.batchToXy(batch) \n",
    "\n",
    "      with pt.no_grad():\n",
    "          loss = pt.nn.functional.mse_loss(self.forward(X), y)\n",
    "\n",
    "      for k,v in {\n",
    "          \"test_mse\": loss.item(),\n",
    "          \"test_rmse\": loss.sqrt().item(),\n",
    "      }.items():\n",
    "        self.log(k, v, step = self.step, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizers = {'Adam': pt.optim.AdamW,\n",
    "                      'SGD': pt.optim.SGD}\n",
    "        optimizer = optimizers[self.hparams.optimizer]\n",
    "\n",
    "        return optimizer(self.layers.parameters(), \n",
    "                            lr = float(self.hparams.lr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468ca1b9",
   "metadata": {},
   "source": [
    "The entrypoint (in a `trainer.py` file of the `src` directory) to the process of building and testing this version of the model starts by loading DC taxi model instance from the `model_v1` package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3758812c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile src/trainer.py\n",
    "from model_v1 import DcTaxiModel\n",
    "\n",
    "import os\n",
    "import time\n",
    "import kaen\n",
    "import torch as pt\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import torch.distributed as dist\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "\n",
    "from kaen.torch import ObjectStorageDataset as osds\n",
    "        \n",
    "def train(model, train_glob, val_glob, test_glob = None):    \n",
    "    #set the pseudo-random number generator seed\n",
    "    seed = int(model.hparams['seed']) \\\n",
    "                if 'seed' in model.hparams \\\n",
    "                else int( datetime.now().microsecond )\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    pt.manual_seed(seed)\n",
    "    \n",
    "    kaen.torch.init_process_group(model.layers)\n",
    "\n",
    "    trainer = pl.Trainer(gpus = pt.cuda.device_count() \\\n",
    "                            if pt.cuda.is_available() else 0,\n",
    "        max_epochs = 1,\n",
    "        limit_train_batches = int( model.hparams.max_batches ) \\\n",
    "                                 if 'max_batches' in model.hparams else 1,\n",
    "        limit_val_batches = 1,\n",
    "        num_sanity_val_steps = 1,\n",
    "        val_check_interval = min(20, int( model.hparams.max_batches ) ),\n",
    "        limit_test_batches = 1,\n",
    "        log_every_n_steps = 1,\n",
    "        gradient_clip_val=0.5,\n",
    "        progress_bar_refresh_rate = 0, \n",
    "        weights_summary = None,)\n",
    "    \n",
    "    train_dl = \\\n",
    "    DataLoader(osds(train_glob,\n",
    "                    worker = kaen.torch.get_worker_rank(),\n",
    "                    replicas = kaen.torch.get_num_replicas(),\n",
    "                    shard_size = int(model.hparams.batch_size),\n",
    "                    batch_size = int(model.hparams.batch_size),\n",
    "                    storage_options = {'anon': False},                    \n",
    "                   ), \n",
    "               pin_memory = True)\n",
    "\n",
    "    val_dl = \\\n",
    "    DataLoader(osds(val_glob,\n",
    "                    batch_size = int(model.hparams.batch_size),\n",
    "                    storage_options = {'anon': False},                    \n",
    "                   ), \n",
    "               pin_memory = True)\n",
    "\n",
    "    trainer.fit(model, \n",
    "              train_dataloaders = train_dl,\n",
    "              val_dataloaders = val_dl)\n",
    "    if test_glob is not None:      \n",
    "        test_dl = \\\n",
    "          DataLoader(osds(test_glob,\n",
    "                          batch_size = int(model.hparams.batch_size),\n",
    "                          storage_options = {'anon': False},                          \n",
    "                         ), \n",
    "                    pin_memory = True) \n",
    "\n",
    "        trainer.test(model, \n",
    "                    dataloaders=test_dl)\n",
    "\n",
    "    return model, trainer\n",
    "\n",
    "if __name__ == \"__main__\":    \n",
    "    model, trainer = train(DcTaxiModel(**{\n",
    "            \"seed\": \"1686523060\",\n",
    "            \"num_features\": \"8\",\n",
    "            \"num_hidden_neurons\": \"[3, 5, 8]\",\n",
    "            \"batch_norm_linear_layers\": \"1\",\n",
    "            \"optimizer\": \"Adam\",\n",
    "            \"lr\": \"0.03\",\n",
    "            \"max_batches\": \"1\",\n",
    "            \"batch_size\": str(2 ** 18),}),        \n",
    "\n",
    "      train_glob = os.environ['KAEN_OSDS_TRAIN_GLOB'] if 'KAEN_OSDS_TRAIN_GLOB' in os.environ \\\n",
    "                    else 'https://raw.githubusercontent.com/osipov/smlbook/master/train.csv',\n",
    "      val_glob = os.environ['KAEN_OSDS_VAL_GLOB'] if 'KAEN_OSDS_VAL_GLOB' in os.environ \\\n",
    "                    else 'https://raw.githubusercontent.com/osipov/smlbook/master/valid.csv',\n",
    "      test_glob = os.environ['KAEN_OSDS_TEST_GLOB'] if 'KAEN_OSDS_TEST_GLOB' in os.environ \\\n",
    "                    else 'https://raw.githubusercontent.com/osipov/smlbook/master/valid.csv')\n",
    "        \n",
    "    print(trainer.callback_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911c6aa2",
   "metadata": {},
   "source": [
    "Run a simple test to confirm that the implementation works as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07815b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 src/trainer.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb15b425",
   "metadata": {},
   "source": [
    "## Unit testing model training in a local Kaen container"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc07eab8",
   "metadata": {},
   "source": [
    "Ensure that you can authenticate with DockerHub, where you can download the base container image. Once you execute the following code snippet in your Kaen Jupyter environment, you will be prompted to enter your DockerHub username, which is then stored in the `DOCKER_HUB_USER` Python variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1175b2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOCKER_HUB_USER = input()\n",
    "DOCKER_HUB_USER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d786cb4",
   "metadata": {},
   "source": [
    "Next, enter the DockerHub password for your username when prompted based on the following code snippet. Notice that the password is cleared out from the `DOCKER_HUB_PASSWORD` variable after the authentication is finished.\n",
    "\n",
    "You should seen an ouput with a message `Login Succeeded` if you specified valid DockerHub credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce19f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "DOCKER_HUB_PASSWORD = getpass.getpass()\n",
    "!echo \"{DOCKER_HUB_PASSWORD}\" | docker login --username {DOCKER_HUB_USER} --password-stdin\n",
    "DOCKER_HUB_PASSWORD = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75653d6d",
   "metadata": {},
   "source": [
    "The base PyTorch Docker image is quite large, at about 1.9 GB. The Kaen base PyTorch image (`kaenai/pytorch-mlflow-aws-base:latest`), which adds binaries with support for AWS and MLFlow is roughly 2 GB in size so be prepared that the following download will take a few minutes, depending on the speed of your internet connection.\n",
    "\n",
    "To execute the download, run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbf607d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker pull kaenai/pytorch-mlflow-aws-base:latest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a72a00",
   "metadata": {},
   "source": [
    "Once the download completes, you can package your source code to an image derived from `kaenai/pytorch-mlflow-aws-base:latest` using the following `Dockerfile`. Notice that the file simply copies the Python source code to the `/workspace` directory of the image file system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ba96bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile Dockerfile\n",
    "FROM kaenai/pytorch-mlflow-aws-base:latest\n",
    "COPY *.py /workspace/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc6e2bf",
   "metadata": {},
   "source": [
    "Since the source code files `model_v1.py` and `trainer.py` described earlier in this chapter were saved to a `src` directory, notice that the following command to build your Docker image uses the `src/` directory as the root of the Docker image build process. To ensure that the image that you build can be uploaded to DockerHub, the image is tagged using `{DOCKER_HUB_USER}` as the image tag prefix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67478619",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker build -t {DOCKER_HUB_USER}/dctaxi:latest -f Dockerfile src/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142e6d63",
   "metadata": {},
   "source": [
    "After the `docker build` command is finished, you can run you newly created Docker container using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b277ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker run -it {DOCKER_HUB_USER}/dctaxi:latest \"python /workspace/trainer.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d005fc2",
   "metadata": {},
   "source": [
    "which should produce the output identical to the output of running the code using `python src/trainer.py`.\n",
    "\n",
    "To push (upload) your newly built image to DockerHub, execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a06e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker push {DOCKER_HUB_USER}/dctaxi:latest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5f9bca",
   "metadata": {},
   "source": [
    "## Hyperparameter optimization with Optuna\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944570fd",
   "metadata": {},
   "source": [
    "The entire HPO implementation used in this notebook is shown in the following code snippet. Notice that the snippet saves the implementation source code as `hpo.py` file in your `src` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99d184f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile src/hpo.py\n",
    "import optuna\n",
    "import numpy as np\n",
    "from kaen.hpo.optuna import BaseOptunaService\n",
    "\n",
    "class DcTaxiHpoService(BaseOptunaService):\n",
    "  def hparams(self):\n",
    "    trial = self._trial\n",
    "\n",
    "    #define hyperparameters\n",
    "    return {\n",
    "        \"seed\": trial.suggest_int('seed', 0, np.iinfo(np.int32).max - 1),\n",
    "        \"optimizer\": trial.suggest_categorical('optimizer', ['Adam']),        \n",
    "        \"lr\": trial.suggest_loguniform('lr', 0.001, 0.1),\n",
    "        \"num_hidden_neurons\": [trial.suggest_categorical(f\"num_hidden_layer_{layer}_neurons\", [7, 11, 13, 19, 23]) \\\n",
    "                                for layer in range(trial.suggest_categorical('num_layers', [11, 13, 17, 19]))],\n",
    "        \"batch_size\": trial.suggest_categorical('batch_size', [2 ** i for i in range(16, 22)]),\n",
    "        \"max_batches\": trial.suggest_int('max_batches', 40, 400, log = True)\n",
    "    }\n",
    "\n",
    "  def on_experiment_end(self, experiment, parent_run):\n",
    "    study = self._study\n",
    "    try:\n",
    "      for key, fig in {\n",
    "        \"plot_param_importances\": optuna.visualization.plot_param_importances(study),\n",
    "        \"plot_parallel_coordinate_all\": optuna.visualization.plot_parallel_coordinate(study, params=[\"max_batches\", \"lr\", \"num_hidden_layer_0_neurons\", \"num_hidden_layer_1_neurons\", \"num_hidden_layer_2_neurons\"]),\n",
    "        \"plot_parallel_coordinate_l0_l1_l2\": optuna.visualization.plot_parallel_coordinate(study, params=[\"num_hidden_layer_0_neurons\", \"num_hidden_layer_1_neurons\", \"num_hidden_layer_2_neurons\"]),\n",
    "        \"plot_contour_max_batches_lr\": optuna.visualization.plot_contour(study, params=[\"max_batches\", \"lr\"]),\n",
    "      }.items():\n",
    "        fig.write_image(key + \".png\")\n",
    "        self.mlflow_client.log_artifact(run_id = parent_run.info.run_id, \n",
    "                            local_path = key + \".png\")\n",
    "        \n",
    "    except:\n",
    "      print(f\"Failed to correctly persist experiment visualization artifacts\")\n",
    "      import traceback\n",
    "      traceback.print_exc()\n",
    "              \n",
    "    #log the dataframe with the study summary  \n",
    "    study.trials_dataframe().describe().to_html(experiment.name + \".html\")  \n",
    "    self.mlflow_client.log_artifact(run_id = parent_run.info.run_id, \n",
    "                        local_path = experiment.name + \".html\")\n",
    "          \n",
    "    #log the best hyperparameters in the parent run\n",
    "    self.mlflow_client.log_metric(parent_run.info.run_id, \"loss\", study.best_value)\n",
    "    for k, v in study.best_params.items():\n",
    "      self.mlflow_client.log_param(parent_run.info.run_id, k, v)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ece13a",
   "metadata": {},
   "source": [
    "With the source code in place, you are ready to package it as a Docker container. Start by pulling a base Kaen container for Optuna and MLFlow:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bda170",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker pull kaenai/optuna-mlflow-hpo-base:latest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e452a21",
   "metadata": {},
   "source": [
    "and once that's finished, create a Dockerfile for a derived image using the following cell.\n",
    "\n",
    "Notice that the package prefix for your `DcTaxiHpoService` implementation corresponds to the filename `hpo.py` as specified by the `KAEN_HPO_SERVICE_NAME` and the `KAEN_HPO_SERVICE_PREFIX` environment variables respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db910e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile Dockerfile\n",
    "FROM kaenai/optuna-mlflow-hpo-base:latest\n",
    "ENV KAEN_HPO_SERVICE_PREFIX=hpo \\\n",
    "    KAEN_HPO_SERVICE_NAME=DcTaxiHpoService\n",
    "\n",
    "COPY hpo.py /workspace/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318ff789",
   "metadata": {},
   "source": [
    "Once the `Dockerfile` is saved, build the image by running"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eca24cf",
   "metadata": {},
   "source": [
    "!docker build -t {DOCKER_HUB_USER}/dctaxi-hpo:latest -f Dockerfile src/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9dc0bc",
   "metadata": {},
   "source": [
    "and push it to DockerHub using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c0934d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker push {DOCKER_HUB_USER}/dctaxi-hpo:latest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe5d116",
   "metadata": {},
   "source": [
    "## Enabling MLFlow support"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10677b7d",
   "metadata": {},
   "source": [
    "Although the base `kaenai/pytorch-mlflow-aws-base:latest` image includes support for MLFlow, the implementation of training in `trainer.py` does not take advantage of the MLFlow experiment management and tracking. Since MLFlow uses the concept of an experiment to organize a collection of HPO trials and run, Kaen provides a `BaseMLFlowClient` class, which can be used to implement an MLFlow managed experiment for DcTaxiModel. The subclasses of `BaseMLFlowClient` are responsible for instantiating the untrained PyTorch model instances using the hyperparameter values that `BaseMLFlowClient` fetches from MLFlow and Optuna.\n",
    "\n",
    "Start by saving an instance of your `BaseMLFlowClient` subclass named `DcTaxiExperiment` by running the following to save the code to train your model to the `src/experiment.py` file.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f4dce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile src/experiment.py\n",
    "import os\n",
    "from model_v1 import DcTaxiModel\n",
    "from trainer import train\n",
    "from kaen.hpo.client import BaseMLFlowClient\n",
    "\n",
    "class DcTaxiExperiment(BaseMLFlowClient):\n",
    "    \n",
    "    def on_run_start(self, run_idx, run):\n",
    "        print(f\"{run}({run.info.status}): starting...\")\n",
    "\n",
    "        #create a set of default hyperparameters\n",
    "        default_hparams = {\"seed\": \"1686523060\",\n",
    "                        \"num_features\": \"8\",\n",
    "                        \"num_hidden_neurons\": \"[3, 5, 8]\",\n",
    "                        \"batch_norm_linear_layers\": \"1\",\n",
    "                        \"optimizer\": \"Adam\",\n",
    "                        \"lr\": \"0.03\",\n",
    "                        \"max_batches\": \"1\",\n",
    "                        \"batch_size\": str(2 ** 18),}        \n",
    "        \n",
    "        #fetch the MLFlow hyperparameters if available\n",
    "        hparams = run.data.params if run is not None \\\n",
    "                    and run.data is not None else \\\n",
    "                    default_hparams\n",
    "        \n",
    "        #override the defaults with the MLFlow hyperparameters\n",
    "        hparams = {**default_hparams, **hparams}\n",
    "\n",
    "        untrained_model = DcTaxiModel(**hparams)\n",
    "        def log(self, k, v, **kwargs):\n",
    "            if self.mlflow_client and 0 == int(os.environ['KAEN_RANK']):\n",
    "                if 'step' in kwargs and kwargs['step'] is not None:\n",
    "                    self.mlflow_client.log_metric(run.info.run_id, k, v, step = kwargs['step']) \n",
    "                else:\n",
    "                    self.mlflow_client.log_metric(run.info.run_id, k, v)                                    \n",
    "                    \n",
    "        import types        \n",
    "        untrained_model.log = types.MethodType(log, self)\n",
    "        \n",
    "        model, trainer = train(untrained_model,\n",
    "                               train_glob = os.environ['KAEN_OSDS_TRAIN_GLOB'],\n",
    "                               val_glob = os.environ['KAEN_OSDS_VAL_GLOB'],\n",
    "                               test_glob = os.environ['KAEN_OSDS_TEST_GLOB'])\n",
    "        \n",
    "        print(trainer.callback_metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def09d4e",
   "metadata": {},
   "source": [
    "With the experiment support in place, you are ready to build the updated `dctaxi` image using \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949b1138",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile Dockerfile\n",
    "FROM kaenai/pytorch-mlflow-aws-base:latest\n",
    "COPY * /workspace/\n",
    "ENV KAEN_HPO_CLIENT_PREFIX=experiment \\\n",
    "    KAEN_HPO_CLIENT_NAME=DcTaxiExperiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ee5d24",
   "metadata": {},
   "source": [
    "Build your `dctaxi` image using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6915e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker build -t {DOCKER_HUB_USER}/dctaxi:latest -f Dockerfile src/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f8e828",
   "metadata": {},
   "source": [
    "and push it to DockerHub using \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5d404a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker push {DOCKER_HUB_USER}/dctaxi:latest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5321423c",
   "metadata": {},
   "source": [
    "## Using HPO for `DcTaxiModel` in a local Kaen provider\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ef3711",
   "metadata": {},
   "source": [
    "Before provisioning the more expensive cloud provider, it is a good idea to start by provisioning a local Kaen provider so you can unit test your HPO and model training code. You can create a Kaen training \"dojo\" by executing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41a7f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaen dojo init --provider local"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6205db7",
   "metadata": {},
   "source": [
    "which should return an alphanumeric identifier for the newly created Kaen dojo. \n",
    "\n",
    "You can list available Kaen dojos in your workspace using "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb58fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaen dojo ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba9367a",
   "metadata": {},
   "source": [
    "\n",
    "which should print out the ID of the dojo you just created. \n",
    "\n",
    "Since you are going to want the identifier of the dojo saved a Python variable for future use, you can do so using the Jupyter syntax for assignment of bash scripts to Python variables as follows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547be41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "[MOST_RECENT_DOJO] = !kaen dojo ls | head -n 1\n",
    "MOST_RECENT_DOJO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68492b4f",
   "metadata": {},
   "source": [
    "Before a Kaen dojo can be used for training, it should be activated. Activate the dojo specified by the identifier in the `MOST_RECENT_DOJO` variable by running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5ca61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaen dojo activate {MOST_RECENT_DOJO}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba09d11",
   "metadata": {},
   "source": [
    "Since the Jupyter `!` shell shortcut provides access to Python variables, in the previous code snippet the `{MOST_RECENT_DOJO}` syntax is replaced with the value of the corresponding Python variable.\n",
    "\n",
    "You can confirm that the dojo is active by inspecting it using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c4476f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaen dojo inspect {MOST_RECENT_DOJO}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e38527",
   "metadata": {},
   "source": [
    "which should include an output line with `KAEN_DOJO_STATUS=active`.\n",
    "\n",
    "Before you can start a training job in the dojo, you need to create one specifying both the dojo and the Kaen image for training. \n",
    "\n",
    "To create a job to train the `DcTaxiModel`, execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9b5da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaen job create --dojo {MOST_RECENT_DOJO} --image {DOCKER_HUB_USER}/dctaxi:latest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf41c185",
   "metadata": {},
   "source": [
    "Just as with the dojo, you can save the identifer of the job to a Python variable using\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7be14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "[MOST_RECENT_JOB] = !kaen job ls | head -n 1\n",
    "MOST_RECENT_JOB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d5f323",
   "metadata": {},
   "source": [
    "Every job in Kaen is configured with dedicated networking settings that you can inspect by running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3849d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaen job inspect {MOST_RECENT_JOB}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6270e18a",
   "metadata": {},
   "source": [
    "Since you have not yet enabled HPO for this job, the inspected job settings do not include the information about the HPO image used to serve MLFlow experiment management and Optuna hyperparameter values. You can configure the job with a single run of HPO, by executing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e4bc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaen hpo enable \\\n",
    "--image {DOCKER_HUB_USER}/dctaxi-hpo:latest \\\n",
    "--num-runs 1 \\\n",
    "--service-prefix hpo \\\n",
    "--service-name DcTaxiHpoService \\\n",
    "--port 5001 5001 \\\n",
    "{MOST_RECENT_JOB} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f852d50b",
   "metadata": {},
   "source": [
    "Assuming the `hpo enable` command completes successfully, you can inspect the job again to observe the HPO specific settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1765e4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaen job inspect {MOST_RECENT_JOB}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f7c7aa",
   "metadata": {},
   "source": [
    "Notice that at this time, the output includes the `KAEN_HPO_MANAGER_IP` for the IP address of the internal Docker network (specified by `KAEN_JOB_SUBNET`) that handles the communication across your container instances. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c787178d",
   "metadata": {},
   "source": [
    "At this time, the HPO service should be up and running, so you should be able to access the MLFlow user interface by navigating your browser to http://127.0.0.1:5001 which should show a screen similar to the following. Note that you need to open the MLFlow experiment that starts with a `job` prefix on the left side bar of the MLFlow interface before you can explore the details of the HPO experiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992155b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['MOST_RECENT_JOB'] = MOST_RECENT_JOB\n",
    "\n",
    "os.environ['BUCKET_ID'] = None\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = None\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = None\n",
    "os.environ['AWS_DEFAULT_REGION'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8783ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "echo $BUCKET_ID\n",
    "echo $AWS_ACCESS_KEY_ID\n",
    "echo $AWS_SECRET_ACCESS_KEY\n",
    "echo $AWS_DEFAULT_REGION\n",
    "echo $MOST_RECENT_JOB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fba475",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaen job start \\\n",
    "--replicas 1 \\\n",
    "-e KAEN_HPO_JOB_RUNS 1 \\\n",
    "-e AWS_DEFAULT_REGION $AWS_DEFAULT_REGION \\\n",
    "-e AWS_ACCESS_KEY_ID $AWS_ACCESS_KEY_ID \\\n",
    "-e AWS_SECRET_ACCESS_KEY $AWS_SECRET_ACCESS_KEY \\\n",
    "-e KAEN_OSDS_TRAIN_GLOB \"s3://dc-taxi-$BUCKET_ID-$AWS_DEFAULT_REGION/csv/dev/part*.csv\" \\\n",
    "-e KAEN_OSDS_VAL_GLOB \"s3://dc-taxi-$BUCKET_ID-$AWS_DEFAULT_REGION/csv/test/part*.csv\" \\\n",
    "-e KAEN_OSDS_TEST_GLOB \"s3://dc-taxi-$BUCKET_ID-$AWS_DEFAULT_REGION/csv/test/part*.csv\" \\\n",
    "$MOST_RECENT_JOB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e48281",
   "metadata": {},
   "source": [
    "## Training with Kaen AWS provider"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5d5f4a",
   "metadata": {},
   "source": [
    "To create a Kaen dojo in AWS, you need to use the `--provider aws` setting when running `kaen init`. By default, when use use the `aws` provider, Kaen provisions `t3.micro` instances as both worker and manager nodes in AWS. Although the `t3.micro` instances are low cost defaults suitable for simple demos, for the `DcTaxiModel`, I recommend provisioning `t3.large` instances as follows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5435b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaen dojo init --provider aws --worker-instance-type t3.xlarge --manager-instance-type t3.xlarge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ece8ee4",
   "metadata": {},
   "source": [
    "which upon a successful provisioning should report the dojo ID.\n",
    "\n",
    "To configure the `MOST_RECENT_DOJO` Python variable, you should execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662e19db",
   "metadata": {},
   "outputs": [],
   "source": [
    "[MOST_RECENT_DOJO] = !kaen dojo ls | head -n 1\n",
    "MOST_RECENT_DOJO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e496850",
   "metadata": {},
   "source": [
    "and then activate the dojo using\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a8f759",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaen dojo activate {MOST_RECENT_DOJO}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1427271a",
   "metadata": {},
   "source": [
    "Notice that if you provision underpowered AWS node instances (such as `t3.micro`) the activation process could take a while. Once the activation is finished correctly, you should be able to inspect the Dojo using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f16a219",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaen dojo inspect {MOST_RECENT_DOJO}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661f8996",
   "metadata": {},
   "source": [
    "and the output should include a line that starts with `KAEN_DOJO_STATUS=active` and the timestamp of when the activation completed.\n",
    "\n",
    "Just as with a local provider, to perform training in AWS, you should start by creating a job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b792f3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaen job create --dojo {MOST_RECENT_DOJO} --image {DOCKER_HUB_USER}/dctaxi:latest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fefa1a",
   "metadata": {},
   "source": [
    "Unlike the case of the local provider, running `kaen job create` in the AWS provider may take a while. This is caused by the fact that the `dctaxi` image that you pushed to DockerHub needs to be downloaded to the AWS node in your dojo. After the job is created, you should save the ID of the job to the `MOST_RECENT_JOB` Python variable using\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de82d70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "[MOST_RECENT_JOB] = !kaen job ls | head -n 1\n",
    "os.environ['MOST_RECENT_JOB'] = MOST_RECENT_JOB\n",
    "MOST_RECENT_JOB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cfada2",
   "metadata": {},
   "source": [
    "and then enable HPO for the job using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f84c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaen hpo enable \\\n",
    "--num-runs 1 \\\n",
    "--image {DOCKER_HUB_USER}/dctaxi-hpo:latest \\\n",
    "--service-prefix hpo \\\n",
    "--service-name DcTaxiHpoService \\\n",
    "--port 5001 5001 \\\n",
    "{MOST_RECENT_JOB} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1486c3",
   "metadata": {},
   "source": [
    "Once the `kaen hpo enable` operation is finished, you can open the MLFlow user interface by constructing the URL in your notebook using\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decf8237",
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo \"http://$(kaen dojo inspect {MOST_RECENT_DOJO} | grep KAEN_DOJO_MANAGER_IP | cut -d '=' -f 2):5001\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89667a6a",
   "metadata": {},
   "source": [
    "and navigating to the URL in your browser. \n",
    "\n",
    "Since it may take a few seconds for the MLFlow UI to become available (depending on the performance of your AWS management node instances), you may need to refresh your browser to get access to this interface.\n",
    "\n",
    "To start the training, the `kaen job start` command is identical to the one you used before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e91b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaen job start \\\n",
    "--replicas 1 \\\n",
    "-e AWS_DEFAULT_REGION $AWS_DEFAULT_REGION \\\n",
    "-e AWS_ACCESS_KEY_ID $AWS_ACCESS_KEY_ID \\\n",
    "-e AWS_SECRET_ACCESS_KEY $AWS_SECRET_ACCESS_KEY \\\n",
    "-e KAEN_OSDS_TRAIN_GLOB \"s3://dc-taxi-$BUCKET_ID-$AWS_DEFAULT_REGION/csv/dev/part*.csv\" \\\n",
    "-e KAEN_OSDS_VAL_GLOB \"s3://dc-taxi-$BUCKET_ID-$AWS_DEFAULT_REGION/csv/test/part*.csv\" \\\n",
    "-e KAEN_OSDS_TEST_GLOB \"s3://dc-taxi-$BUCKET_ID-$AWS_DEFAULT_REGION/csv/test/part*.csv\" \\\n",
    "$MOST_RECENT_JOB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f39f23",
   "metadata": {},
   "source": [
    "As in the case with the local provider, you can navigate your browser to the MLFlow UI and monitor the metrics as the model trains.\n",
    "\n",
    "## When you are done, do not forget to remove the AWS training dojo using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfd1af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaen dojo rm {MOST_RECENT_DOJO}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
